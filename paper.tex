\documentclass{article}
\usepackage[round]{natbib}

\usepackage{listings}

\lstset{language=Python}

% local definitions
\newcommand{\msprime}[0]{\texttt{msprime}}
\newcommand{\ms}[0]{\texttt{ms}}
\newcommand{\stdpopsim}[0]{\texttt{stdpopsim}}


\begin{document}

\title{Describing demographic models is hard}
\author{A permutation of (AR, DN, JK, SG)}
\maketitle

\abstract{
We describe two errors made in defining population genetic models using the
\msprime\ coalescent simulator.

}

\section*{Introduction}

The \msprime\ coalescent simulator~\citep{kelleher2016efficient,kelleher2020coalescent}
is now quite widely used. The large increases in efficiency over the classical
\ms\ program~\citep{hudson2002generating} make it feasible to simulate large
samples of whole chromosomes for the first time. Another distinct advantage
of \msprime\ is the Python API that is its primary interface, greatly
increasing the flexibility and efficiency over the standard approach of
text-based command line interfaces. In particular, programs like \ms\
required users to specify cryptic command line options to describe demographic
models [JK: maybe include an example ms command line?]. Particularly for
the large models we are using today, these are not comprehensible for humans.
The Python API for \msprime\ is a great improvement, allowing the user to
state models in a documented and reproducible manner. [JK: maybe show
the same model as described above in msprime notation?]

Describing these models of population history is still hard and error
prone, however. In this note we discuss how two poor design decisions
in \msprime's demography API lead to errors being made, which ended
up in the scientific record.

\section{A bad tutorial example}

To illustrate the demography API, \msprime\ included a description of a widely-used
three population Out-of-Africa model~\citep{gutenkunst2009inferring}
as part of its tutorial documentation. This example model, however,
was not correctly implemented.

[What's wrong with the model, and how does this differ from the original. Some
analysis.]

This model was subsequently copied
several times and used in papers [JK: do we want to estimate how
many times it was copied? A quick search on github suggests around 30
times].

Arguably, this error occured because of a poor API design choice.
The MassMigration event is confusing and poorly explained. In
\msprime\ 1.0 we're introducing a PopulationSplit event, which allows
such models to be described more declaritively.

\section{A missing parameter}

In another publication using this model~\citep{martin2017human}, 
another error crept in: the model itself was defined as suggested 
in the documentation, and tested using model visualization and 
debugging tools. After these checks were performed, however, the simulation 
itself was finally performed with an incorrect parameter, leading to a vast 
overestimate of the divergence across human populations. 

In this case the error had a large effect on the simulation output and 
the conclusions of the analysis. This simulation was performed to assess 
the transferabilty of polygenic risk scores across human populations. 

Unfortunately, whereas the correct model suggests a mean $F_{ST}$ of 
XXX across the three population, the simulated model generated an $F_{ST}$ of 
XXX, exaggerating the difficulty in transferring genetic risk across populations (the difficulty still exists, Figure X).  The resulting
publication has been influential in the discussion of health inequalities and 
genomics, [[with over 350 citations since 2017 ?]]. 

This particular error suggests three lessons. 

First, the msprime API design was poorly designed, requiring the user to pass
three separate parameters to specify a demographic model. 
 In \msprime\ 1.0 we introduce
a Demography class, which wraps these three parameters.
Thus, instread of writing
\begin{lstlisting}[frame=single]
dbg = msprime.DemographyDebugger(
    population_configurations=population_configurations,
    migration_matrix=migration_matrix,
    demographic_events=demographic_events)
dbg.print_history()
ts = msprime.simulate(
    population_configurations=population_configurations,
    migration_matrix=migration_matrix,
    demographic_events=demographic_events)
\end{lstlisting}
we would now write
\begin{lstlisting}[frame=single]
dbg = demography.debug()
dbg.print_history()
ts = msprime.simulate(demography=demography)
\end{lstlisting}.

Second, testing of the final simulated data is important. This can be challenging, 
because the amount of simulated data can be large. However, recent progress in 
computing summary statistics from tree sequence data \cite{} can make this easier. 
Even if the entire simulation data cannot be easily evaluated, subsets of the data 
can be examined to identify large error.  

Third, open data analysis pipelines are necessary for the self-correcting nature of science. 
This subtle error of large effect was only discovered as one of us was trying to take
advantage of the simulation pipeline developed in~\citep{martin2017human} to pursue 
additional analyses on a similar topic. We identified the bug by tracing down an unexpected 
result in our analysis.  

\section{Conclusions}

Stuff to mention in no particular order:
\begin{itemize}
\item Defining demographic models is hard, and we need all the help we can get.
   We really need \stdpopsim.
\item If you do have to implement your own models, make sure that it is
verified. Getting someone else to implement it is a good approach (following
stdpopsim's QC procedure.)
\item It's really important to do some basic sanity checking on your
simulations. If your simulations are really big, do some small sims first and
analysis on this to make that basic properties hold.
\item Openness is essential. We only know about these errors because of
open code and open source development processes. There must be many, many more
out there.
\item API design matters! A lot!!
\end{itemize}

\bibliographystyle{plainnat}
\bibliography{paper}

\end{document}
